{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "115889c5",
   "metadata": {},
   "source": [
    "# Lab-P13: Analyzing World Data with SQL\n",
    "\n",
    "In this lab, you'll get practice with writing SQL queries and various plotting functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daed65a3",
   "metadata": {},
   "source": [
    "# Segment 1: Setup\n",
    "\n",
    "### Task 1.1: Import the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59b7bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: import sqlite3, pandas, os, requests, math, and matplotlib\n",
    "# TODO: display matplotlib plots using %matplotlib inline \n",
    "import numpy as np #This is *only* for the function get_regression_coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75adca21",
   "metadata": {},
   "source": [
    "### Task 1.2: Write a download function to download QSRankings.json and save it to your lab folder\n",
    "\n",
    "Warning: For the lab and the project, do not download the dataset QSranking.json manually (you must write Python code to download this automatically, as in p12). When we run the autograder, this file QSranking.json will not be in the directory. So, unless your main.ipynb downloads this file, you will get a zero score on the project. Also, make sure your download function includes code to check if the file already exists. The TAs will manually deduct points otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb742ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copy your download function from p12 and download QSRanking.json\n",
    "\n",
    "\n",
    "# Make sure your download function works by downloading QSRankings.json:\n",
    "download(\"https://raw.githubusercontent.com/msyamkumar/cs220-s22-projects/main/p13/QSranking.json\", \"QSranking.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0023581a",
   "metadata": {},
   "source": [
    "### Task 1.3: Create a database called 'rankings.db' out of 'QSRankings.json'\n",
    "\n",
    "Check out the [Database 1](https://github.com/tylerharter/caraza-harter-com/blob/master/tyler/meena/cs220/s22/materials/meena_lec_notes/lec-32/lec_32_database1.ipynb) lecture for information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270d8da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load the data from QSranking.json into a variable called df1 using pandas's read_json\n",
    "\n",
    "# TODO: connect to 'rankings.db' and save it to a variable called conn\n",
    "\n",
    "\n",
    "# We'll give you this line since it wasn't covered in lecture\n",
    "# It writes a dataframe's contents to a sqlite database\n",
    "df1.to_sql(\"rankings\", conn, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a77c79",
   "metadata": {},
   "source": [
    "### Task 1.4: Read all the rows in rankings (the database table)\n",
    "\n",
    "You'll have to use pandas's read_sql function to make a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a300adde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use pandas's read_sql function to query all rows in rankings. Save this to a variable called df\n",
    "\n",
    "\n",
    "assert len(df) == 1201\n",
    "assert df.iloc[0][\"country\"] == \"United States\"\n",
    "assert df.iloc[-1][\"institution_name\"] == \"Wake Forest University\"\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b09ee5a",
   "metadata": {},
   "source": [
    "# Segment 2: SQL Practice\n",
    "\n",
    "In practice, we often are more interested in writing more specific queries about our data. For example, we might be interested in finding institutions in the United States, or data collected in the year 2018, or both. With SQL, WHERE and AND clauses can help filter the data accordingly.\n",
    "\n",
    "### Task 2.1: Use WHERE to find institutions in the United States\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64012949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a query to select the rows from the database with 'United States' as the `country`.\n",
    "# TODO: Keep only the institution_name column, remove any duplicate names.\n",
    "# TODO: Save these institution names to a list (not DataFrame!) called US_institutions.\n",
    "\n",
    "assert \"University Of Wisconsin-Madison\" in US_institutions\n",
    "assert \"Tampere University\" not in US_institutions\n",
    "assert \"Tampere University\" in list(df[\"institution_name\"])\n",
    "US_institutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe4da4e",
   "metadata": {},
   "source": [
    "### Task 2.2 Add an AND clause to find institutions in the United States with at least 70 overall score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f341ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copy your query from task 2.1, and update it to only select rows with an overall score of atleast 70\n",
    "\n",
    "assert \"Massachusetts Institute Of Technology\" in US_institutions\n",
    "assert \"University Of Wisconsin-Madison\" in US_institutions\n",
    "assert \"Wake Forest University\" not in US_institutions\n",
    "assert \"University of Connecticut\" not in US_institutions\n",
    "US_institutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf715227",
   "metadata": {},
   "source": [
    "### Task 2.3 Use an ORDER BY clause to display the top 5 institutions by academic reputation in 2019\n",
    "\n",
    "In addition to WHERE and AND, the ORDER BY keyword helps organize data even further. Much like the sort_values() function in pandas, the ORDER BY clause can be used to organize the result of the query in increasing (ASC) or decreasing (DESC) order based on a column's values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404fa832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a new query to select rows in rankings where the year is 2019.\n",
    "# TODO: Use ORDER BY and LIMIT to select the top 5 rows with the highest academic_reputation.\n",
    "# TODO: Save these institution names to a list (not DataFrame!) called top_5.\n",
    "\n",
    "\n",
    "assert len(top_5) == 5\n",
    "assert top_5[0] == \"Massachusetts Institute Of Technology\"\n",
    "assert top_5[-1] == \"University Of Cambridge\"\n",
    "top_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e1803b",
   "metadata": {},
   "source": [
    "### Task 2.4 Update your query from task 2.3 to sort institutions in 2019 by academic reputation, then by citations_per_faculty\n",
    "\n",
    "If you print out the resulting dataframe from your query, you might notice that all 5 rows have the same academic reputation. This makes it hard to compare the universities, so we will add some tiebreaking rules. If two universities have the same academic_reputation, then we should compare them by citations_per_faculty instead. Sometimes, in conversation, programmers abbreviate this by saying: \"sort by academic_reputation, then by citations_per_faculty\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b2382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copy your query from task 2.3, and modify the ORDER BY to add this tiebreaking behavior.\n",
    "# TODO: Save these institution names to a list (not DataFrame!) called top_5_with_tiebreak.\n",
    "\n",
    "assert top_5_with_tiebreak[0] == \"University Of California, Berkeley\"\n",
    "assert top_5_with_tiebreak[-1] == \"University Of California, Los Angeles\"\n",
    "top_5_with_tiebreak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b991dcf",
   "metadata": {},
   "source": [
    "### Task 2.5 Use a GROUP BY clause and SUM aggregate function to get the total number of international_students for each country in 2019\n",
    "\n",
    "The GROUP BY keyword groups rows that have the same value. It is often used with aggregate functions, such as COUNT, SUM, AVG, etc. to obtain a summary about groups in the data.\n",
    "\n",
    "For example, to answer the question \"What is the average rank of each country's institutions?\", we could GROUP BY the country and use the AVG aggregate function to get the average rank of each country.\n",
    "\n",
    "The output of your query will be a DataFrame with 2 columns: country and the sum of the international_students for that country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c84f12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a new query that uses GROUP BY and SUM to get the total number of international students in each country\n",
    "# TODO: Save the resulting DataFrame into a variable called intl_students_by_country.\n",
    "\n",
    "assert math.isclose(intl_students_by_country[intl_students_by_country[\"country\"] == \"Japan\"].iloc[0][1], 280.9)\n",
    "assert math.isclose(intl_students_by_country[intl_students_by_country[\"country\"] == \"Australia\"].iloc[0][1], 1895.5)\n",
    "assert math.isclose(intl_students_by_country[intl_students_by_country[\"country\"] == \"United States\"].iloc[0][1], 3675.0)\n",
    "intl_students_by_country"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ecba29",
   "metadata": {},
   "source": [
    "### Task 2.6 Use the AS keyword to rename the new column from task 2.5 to total_international_students\n",
    "\n",
    "Although the dataframe does have a column for the sum of international students for each country, the name of the column looks strange:\n",
    "\n",
    "```\n",
    "SUM(`international_students`)\n",
    "```\n",
    "\n",
    "In SQL, the AS keyword allows us to rename the columns we create with our queries to make the resulting dataframe easier to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e114959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Paste your query from task 2.5 and modify it so the SUM column has the name total_international_students\n",
    "# TODO: Save the resulting DataFrame into a variable called intl_students_by_country_renamed.\n",
    "\n",
    "assert \"total_international_students\" in intl_students_by_country_renamed.columns\n",
    "assert math.isclose(intl_students_by_country_renamed[intl_students_by_country_renamed[\"country\"] == \"Japan\"][\"total_international_students\"], 280.9)\n",
    "assert math.isclose(intl_students_by_country_renamed[intl_students_by_country_renamed[\"country\"] == \"Australia\"][\"total_international_students\"], 1895.5)\n",
    "assert math.isclose(intl_students_by_country_renamed[intl_students_by_country_renamed[\"country\"] == \"United States\"][\"total_international_students\"], 3675.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fdda0c",
   "metadata": {},
   "source": [
    "### Task 2.7 Use the HAVING keyword to only keep countries with more than 1000 international students\n",
    "\n",
    "In addition to WHERE, the HAVING keyword is useful for filtering GROUP BY queries. Whereas WHERE filters the number of rows, HAVING filters the number of groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c5be56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Paste your query from task 2.6 and modify it so that it only returns countries and total_international_students with more than 1000 international students\n",
    "# TODO: Save the resulting DataFrame into a variable called intl_students_by_country_more_than_1000\n",
    "\n",
    "assert len(intl_students_by_country_more_than_1000) == 4\n",
    "assert \"Australia\" in list(intl_students_by_country_more_than_1000[\"country\"])\n",
    "assert \"Germany\" in list(intl_students_by_country_more_than_1000[\"country\"])\n",
    "assert \"United Kingdom\" in list(intl_students_by_country_more_than_1000[\"country\"])\n",
    "assert \"United States\" in list(intl_students_by_country_more_than_1000[\"country\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055d7f44",
   "metadata": {},
   "source": [
    "# Segment 3: Plotting\n",
    "\n",
    "SQL provides powerful tools to manipulate and organize data. Now we might be interested in plotting the data to engage in data exploration and visualize our results.\n",
    "\n",
    "In the below plotting functions, `df` is the DataFrame containing the data to plot, `x` is the name of the column to plot on the x-axis, and `y` is the name of the column to plot on the y-axis.\n",
    "\n",
    "### Task 3.1: Use a bar plot to plot the data from task 2.7\n",
    "\n",
    "Your plot should look like this:\n",
    "\n",
    "![Bar Plot Image](https://github.com/msyamkumar/cs220-s22-projects/raw/main/lab-p13/images/barplot.png/)\n",
    "\n",
    "See these lectures for reference:  \n",
    "[Line Plots and Stacked/Clustered Bar Plots](https://github.com/tylerharter/caraza-harter-com/blob/master/tyler/meena/cs220/s22/materials/readings/line-and-bar.ipynb)  \n",
    "[Matplotlib Intro](https://github.com/tylerharter/caraza-harter-com/blob/master/tyler/meena/cs220/s22/materials/readings/matplotlib-intro.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4dc5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot(df, x, y):\n",
    "    # TODO: Use df.plot.bar to plot the data in black with no legend\n",
    "    # TODO: set x as the x label \n",
    "    # TODO: set y as the y label\n",
    "    # TODO: set the color to black\n",
    "    pass\n",
    "    \n",
    "# TODO: Use the bar_plot function to show the data from task 2.7. The country\n",
    "# name should be on the x axis, and total_international_students should be\n",
    "# on the y axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a10878",
   "metadata": {},
   "source": [
    "### Task 3.2: Use a scatter plot to plot the relationship between employer_reputation and academic_reputation in 2019\n",
    "\n",
    "Your plot should look like this: ![Scatter Plot Image](https://github.com/msyamkumar/cs220-s22-projects/raw/main/lab-p13/images/scatterplot.png/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb6036d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot(df, x, y):\n",
    "    # TODO: Use df.plot.scatter to plot the data in black with no legend\n",
    "    # TODO: set x as the x label \n",
    "    # TODO: set y as the y label\n",
    "    # TODO: set the color to black\n",
    "    pass\n",
    "    \n",
    "# TODO: Write a query to select rows from the database where the year is 2019\n",
    "# TODO: Call scatter_plot(), passing in employer_reputation and academic_reputation\n",
    "# column names as x and y respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aa3b4e",
   "metadata": {},
   "source": [
    "### Task 3.3 Make a Horizontal Bar plot of average employer_reputation and average faculty_student_score across all years\n",
    "\n",
    "Your plot should look like this:\n",
    "![Horizontal Bar Plot Image](https://github.com/msyamkumar/cs220-s22-projects/raw/main/lab-p13/images/horizontalbarplot.png/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e21b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_horizontal_bar(df, x):\n",
    "    df = df.set_index(x)\n",
    "    ax = df.plot.barh()\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.9))\n",
    "\n",
    "# TODO: Write a query to select year, average employer reputation, and average faculty student score grouped by year\n",
    "# TODO: Use plot_horizontal bar to plot the resulting dataframe by \"year\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f54499",
   "metadata": {},
   "source": [
    "### Task 3.4 Display a Pie Chart of the average overall score of the top 10 countries in descending order\n",
    "\n",
    "Your plot should look like this:\n",
    "![Pie Chart Image](https://github.com/msyamkumar/cs220-s22-projects/raw/main/lab-p13/images/piechart.png/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedb58d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pie(df, x, y, title=None):\n",
    "    df = df.set_index(x)\n",
    "    ax = df.plot.pie(y=y, legend=False)\n",
    "    ax.set_ylabel(None)\n",
    "    ax.set_title(title)\n",
    "\n",
    "# TODO: Write a query to select the top 10 countries based on average overall score\n",
    "# TODO: Use plot_pie to illustrate the data, the size of the pie slice is determined by the country's average overall score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feace8c",
   "metadata": {},
   "source": [
    "### Task 3.5 (Optional): Fit a regression line to the data from task 3.2\n",
    "\n",
    "Your line of best fit should look like this:\n",
    "![Regression Line](https://github.com/msyamkumar/cs220-s22-projects/raw/main/lab-p13/images/regression.png/)\n",
    "\n",
    "\n",
    "This Task is optional, which means you may start the project before finishing it. However, you will still need to do this task eventually to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065d0ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df: A dataframe\n",
    "\n",
    "# x: The name of a column in df. The values in this column will be used\n",
    "# as the x-axis values (independent variable)\n",
    "\n",
    "# y: The name of a column in df. The values in this column will be used\n",
    "# as the y-axis values (dependent variable)\n",
    "\n",
    "# Returns: the slope (m) and y-intercept (b) of the line of best fit\n",
    "def get_regression_coeff(df, x, y):\n",
    "    df[\"1\"] = 1\n",
    "    res = np.linalg.lstsq(df[[x, \"1\"]], df[y], rcond=None)\n",
    "    coefficients = res[0]\n",
    "    m = coefficients[0]\n",
    "    b = coefficients[1]\n",
    "    return (m, b)\n",
    "\n",
    "def plot_regression_line(df, x, y):\n",
    "    # TODO: Use the get_regression_coeff function to get the slope and\n",
    "    # intercept of the line of best fit. Save them into variables m and b respectively\n",
    "    \n",
    "    # TODO: Use df.plot.scatter (not scatter_plot) to plot the x and y columns in black.\n",
    "    # and save the return value of scatter to a variable called ax\n",
    "    \n",
    "    # TODO: Create a new column in the dataframe called \"fit\", which is\n",
    "    # is calculated according to \"fit\" = m * x + b. x is a value in the\n",
    "    # x column of the dataframe.\n",
    "    \n",
    "    # TODO: Use df.plot.line to plot the fitted line in red, using ax=ax as a keyword argument\n",
    "    # this ensures that both the scatter plot and line end up on the same plot\n",
    "    \n",
    "\n",
    "# TODO: Call plot_regression_line on your data from task 3.2 to show the correlation between\n",
    "# employer_reputation and academic_reputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f20a99c",
   "metadata": {},
   "source": [
    "Good luck with P13!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
