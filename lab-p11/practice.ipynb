{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e25abcbe-c306-460c-863b-3430d8a155bc",
   "metadata": {},
   "source": [
    "# Lab-P11: Files and Formats for Youtube Data\n",
    "\n",
    "In p11 you will be analyzing YouTube data. In lab-p11, we will help you setup the data and some functions that you have already developed in p10 or lab-p10. In addition, we will introduce scatter plots and help you write a recursive function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f68f4d-1317-4277-8a35-5939742861cd",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37d1b29-2129-4eee-8c6a-7be2c62417bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "\n",
    "# add code to import the os module\n",
    "# add code to import the csv module\n",
    "# add code to import the json module\n",
    "# add code to import the pandas module\n",
    "# add code to import the matplotlib module\n",
    "# add code to import nametuple type *from* collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3d984a-8ed0-450d-b61e-5faadebbea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5680d59f-b42d-4d14-b6a3-a615571f0218",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4964142e-fb29-4311-9e82-7d6c1ee51267",
   "metadata": {},
   "source": [
    "## Segment 1: Setup\n",
    "### Task 1: Build helper functions for project preparation\n",
    "\n",
    "We need to borrow some codes from p10 and lab-p10 to here, these functions are what you need in p11. Helper functions are listed below:\n",
    "\n",
    "* `read_json(path)` (from lab-p10)\n",
    "* `get_mapping(pathname)` (from p10)\n",
    "* `Comment` type definition (from p10)\n",
    "* `get_comment_data(comment_file)` (from p10)\n",
    "* `bucketize(attribute, videos)` (from p10)\n",
    "* `plot_dict(d, label=\"Please Label Me!!!\")` (from lab-p9)\n",
    "* `process_csv(filename)` (from lab-p10)\n",
    "* `list_files_in(pathname)` (from lab-p10)\n",
    "* `list_paths_in(pathname)` (from lab-p10)\n",
    "* Invocation of `list_paths_in` (from p10)\n",
    "* Code to populate `comment_paths` (from p10)\n",
    "* Code to populate `channel_paths` (from p10)\n",
    "* Code to populate `channel_dict` (from p10)\n",
    "* Code to populate `comments` (from p10)\n",
    "* Code to populate `comment_buckets` (from p10)\n",
    "* `get_videos(data_file, video_mapping_file)` (from p10)\n",
    "\n",
    "\n",
    "Make sure to download data.zip from Github and extract it to your lab11 folder.\n",
    "\n",
    "**P.S. If you havenâ€™t finished P10, go straight to Segment 2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191503db-d845-4ed5-b8be-461dbca1e257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This entire cell should be pasted into your P11 notebook\n",
    "\n",
    "## From lab-p10\n",
    "def read_json(path):\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "## From p10 (Q5)\n",
    "def get_mapping(pathname):\n",
    "    pass\n",
    "\n",
    "## From p10 (Q7)\n",
    "## `Comment` type definition\n",
    "\n",
    "## From p10 (Q7)\n",
    "def get_comment_data(comment_file):\n",
    "    pass\n",
    "\n",
    "## From p10 (Q17)\n",
    "## Make sure to remove default argument to videos. If you want to retain it,\n",
    "## you will have to define get_videos function before bucketize and make sure\n",
    "## you call get_videos and store the return value into the variable videos\n",
    "def bucketize(attribute, videos):\n",
    "    pass\n",
    "\n",
    "## From lab-p9\n",
    "def plot_dict(d, label=\"Please Label Me!!!\"):\n",
    "    ax = pandas.Series(d).sort_index().plot.bar(color=\"black\", fontsize=16)\n",
    "    ax.set_ylabel(label, fontsize=16)\n",
    "    \n",
    "## From lab-p10\n",
    "def process_csv(filename):\n",
    "    exampleFile = open(filename, encoding=\"utf-8\")  \n",
    "    exampleReader = csv.reader(exampleFile) \n",
    "    exampleData = list(exampleReader)        \n",
    "    exampleFile.close()  \n",
    "    return exampleData\n",
    "\n",
    "## From lab-p10\n",
    "def list_files_in(pathname):\n",
    "    pass\n",
    "\n",
    "## From lab-p10\n",
    "def list_paths_in(pathname):\n",
    "    pass\n",
    "\n",
    "## From p10 (Q2)\n",
    "## Use `list_paths_in` to list all paths in the data directory\n",
    "## Save this to a variable called all_paths\n",
    "\n",
    "## From p10 (Q3)\n",
    "## Code to populate `comment_paths`\n",
    "\n",
    "## From p10 (Q4)\n",
    "## Code to populate `channel_paths` \n",
    "\n",
    "## From p10 (Q6)\n",
    "## Code to populate `channel_dict` \n",
    "\n",
    "## From p10 (Q8)\n",
    "## Code to populate `comments` \n",
    "\n",
    "## From p10 (Q12)\n",
    "## Code to populate `comment_buckets` \n",
    "\n",
    "## From p10\n",
    "def get_videos(data_file, video_mapping_file):\n",
    "    pass\n",
    "\n",
    "## From p10 (Q13), create a dictionary named `videos` and use `get_videos` to fill the information in the \n",
    "## `videos`.\n",
    "## Populate the variable named `videos` to answer\n",
    "videos = get_videos(???, ???)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c4296f-2a51-45b8-baa9-778394f939b2",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7f35cd-803e-4bee-8183-db3cd39fbe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display all_paths, defined above, here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8243e870-8693-49c3-ab60-28c07bbdca56",
   "metadata": {},
   "source": [
    "You can display your all_files, and it should look like:\n",
    "```python\n",
    "['data/channel_ids1.json',\n",
    " 'data/channel_ids2.json',\n",
    " 'data/channel_ids3.json',\n",
    " 'data/channel_ids4.json',\n",
    " 'data/channel_ids5.json',\n",
    " 'data/comment_data1.csv',\n",
    " 'data/comment_data2.csv',\n",
    " 'data/comment_data3.csv',\n",
    " 'data/comment_data4.csv',\n",
    " 'data/comment_data5.csv',\n",
    " 'data/video_data.csv',\n",
    " 'data/video_ids.json']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da52fcf0-3a4b-4ddf-83ca-f8fcf63595f7",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4861986e-b636-4240-9d73-143ee9c27f04",
   "metadata": {},
   "source": [
    "Are you able to understand what the below code checks? TODO: discuss with your lab partner.\n",
    "If any of the following assertions fail, check your code! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b0d3cf-2341-45ec-b842-1f2f96094c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "## From p10 (Q4), What are the paths of all the files whose name contains `channel_ids` in our data directory?\n",
    "## Let's do some verification\n",
    "\n",
    "for idx in range(len(channel_paths)):\n",
    "    path = channel_paths[idx]\n",
    "    assert path == 'data/channel_ids' + str(idx + 1) + '.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60057ec3-fc78-486f-914a-e2f8bb94042f",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e57f8e-4bf9-4a27-8f5e-5466e0764ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## From p10 (Q6), create a mapping dictionary for channel ID and the name of channel\n",
    "## Let's verify our `channel_dict`\n",
    "\n",
    "assert len(channel_dict) == 372\n",
    "assert channel_dict[\"UCpi8TJfiA4lKGkaXs__YdBA\"] == 'The Try Guys'\n",
    "assert channel_dict[\"UCERUmrDh9hmqEXBsnYFNTIA\"] == 'DashieGames'\n",
    "assert channel_dict[\"UC3xZYc4SZUGfRERIvDRGqDQ\"] == 'Skip the Tutorial'\n",
    "assert channel_dict[\"UCfLuMSIDmeWRYpuCQL0OJ6A\"] == 'Kwebbelkop'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84893b72-d02b-4a0c-b717-29507ec0ebef",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df55e65d",
   "metadata": {},
   "source": [
    "If any of the following assertions fail, check your code! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ca4d6b-eab8-4263-aa7f-07a1494f0615",
   "metadata": {},
   "outputs": [],
   "source": [
    "## From p10 (Q3), What are the paths of all the files whose name contains comment_data in our data directory?\n",
    "## Let's do some verification\n",
    "\n",
    "for idx in range(len(comment_paths)):\n",
    "    path = comment_paths[idx]\n",
    "    assert path == 'data/comment_data' + str(idx + 1) + '.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595a9f20-7c9a-4c5e-a5ba-f3c4152b73b9",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbd5b41-9fe8-4584-ab97-8b2d2420f4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## From p10 (Q12), bucketize the comments data by creating a dictionary mapping video IDs to \n",
    "## Let's do some verification\n",
    "\n",
    "assert len(comment_buckets[\"A8rrr_w8rfk\"]) == 606"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1725cbf-52d2-4840-88f5-ea101565016f",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f6955f-1a77-42a3-9a07-aaa4dae891b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert videos['fkMW60W180E']['likes'] == 210951\n",
    "assert videos['fkMW60W180E']['dislikes'] == 1824\n",
    "assert videos['fkMW60W180E']['ratings_enabled'] == True\n",
    "assert videos['UeFnH1DKYIE']['likes'] == None\n",
    "assert videos['UeFnH1DKYIE']['dislikes'] == None\n",
    "assert videos['UeFnH1DKYIE']['ratings_enabled'] == False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959f834c-df03-4096-862f-89857aa1edd7",
   "metadata": {},
   "source": [
    "The functions and data structures you pasted into the first cell of Segment 1 Task 1 are what you need to start p11. Make sure to copy/paste everything in that cell before you start solving p11."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfa0f92-57b8-4f5d-8fdc-1154305596b5",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c571e5-a46a-4112-984b-6f10139c888d",
   "metadata": {},
   "source": [
    "## Segment 2: Recursion\n",
    "\n",
    "As we learned in class, a function is recursive when it calls itself, directly or indirectly. We'll give you some practice here to complete some recursive code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b217468-264e-410d-8048-39a71dc34684",
   "metadata": {},
   "source": [
    "### Task 2.1: Flatten a Nested List\n",
    "\n",
    "We are going to write a recursive function to flatten a nested list and print out all the elements in list. Let's consider the simplest case -> 1-dimensional list. Iterate over the 1-dimensional list and simple populate the items into a new list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02cd6ed-f621-41b0-8a31-2ae45bd7b8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(some_list):\n",
    "    # Initialize an empty list into a variable called collection\n",
    "    # Iterate over every item inside some_list\n",
    "        # Insert each item into the new list\n",
    "        # For now, let's assume some_list is 1-dimensional list\n",
    "        \n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47440b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = ['a', 'b', 'c', 'd']\n",
    "assert flatten(letters) == ['a', 'b', 'c', 'd']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703dc9a6",
   "metadata": {},
   "source": [
    "So, we made it work for a 1-dimensional list. Now would be a good time for you to review `append` vs `extend` list methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9623d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [1, 2, 3, 4]\n",
    "list1.append([4, 5, 6])\n",
    "print(\"Append does this:\", list1)\n",
    "\n",
    "list2 = [1, 2, 3, 4]\n",
    "list2.extend([4, 5, 6])\n",
    "print(\"Extend does this:\", list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c26973",
   "metadata": {},
   "source": [
    "Now that we have done a recap on these list methods, let's go back to finishing our `flatten` function. `flatten` handles the simplest case. Recall that, we use the term base case to denote that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e95e4f4",
   "metadata": {},
   "source": [
    "Let's update it to handle n-dimensional nested lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936c2c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not duplicate the definition of flatten.\n",
    "# Instead, copy and paste these new instructions to the above cell to modify flatten\n",
    "\n",
    "    ### NEW PART ###\n",
    "    # Check whether type of current item is list\n",
    "        # Recursively call flatten on this inner list\n",
    "        # What do you do with the return value? \n",
    "            # For now, print the return value\n",
    "\n",
    "            # TODO: Come back to this step after you test the current version of the function\n",
    "            # Which list method do need to ensure every item in that returned list gets \n",
    "            # added as an item inside collection?\n",
    "    # Otherwise\n",
    "        # Insert each item into the new list\n",
    "        # Remember you already wrote code for this\n",
    "        # Just move the code into the else branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637bf859-253c-4d1a-8ccf-e61fc2328743",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_letters = ['a', ['b', ['c', ['d']], 'e'], 'f']\n",
    "flatten(nested_letters)\n",
    "\n",
    "# Once you see the output of the print function call, go back and address the TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51394150",
   "metadata": {},
   "source": [
    "Are you able to understand what the below code checks? TODO: discuss with your lab partner.\n",
    "If any of the following assertions fail, check your code! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dac1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert flatten(nested_letters) == ['a', 'b', 'c', 'd', 'e', 'f']\n",
    "\n",
    "nested_names_1 = [\"Adam\", [\"Bob\", [\"Chet\", \"Cat\"], \"Barb\", \"Bert\"], \"Alex\", [\"Bea\", \"Treasure\"], \\\n",
    "                  [\"Andy\"], \"Ann\"]\n",
    "assert flatten(nested_names_1) == ['Adam', 'Bob', 'Chet', 'Cat', 'Barb', 'Bert', 'Alex', \\\n",
    "                                   'Bea', 'Treasure', 'Andy', 'Ann']\n",
    "\n",
    "nested_names_2 = [\"Adam\", [\"Bob\", [\"Chet\", \"Cat\"], \"Barb\", \"Bert\"], \"Alex\", [\"Bea\", \"Gold\"], \\\n",
    "                  [\"Andy\"], \"Ann\"]\n",
    "\n",
    "assert flatten(nested_names_2) == ['Adam', 'Bob', 'Chet', 'Cat', 'Barb', 'Bert', 'Alex', \\\n",
    "                                   'Bea', 'Gold', 'Andy', 'Ann']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bc377c-c402-4db2-a499-27af900d7e01",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca9e1f1-0e6f-4971-a73f-7383b79abc1d",
   "metadata": {},
   "source": [
    "### Task 2.2: Explore a Directory Recursively\n",
    "\n",
    "In your Task 2.1, we practiced how to recursively collect elements in a nested list. In Task 2.2, we are going to recursively collect all the paths of files in a given directory. After collecting them, your function `get_all_paths_in` will return a sorted list of paths to files inside this directory. We will use `broken_file` as directory so make sure to download `broken_file.zip` from Github and extract it to your lab11 folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f4c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: invoke listdir function to list files and directories inside \"broken_file\" and sort the returned list\n",
    "\n",
    "broken_file_contents = sorted(???)\n",
    "\n",
    "assert broken_file_contents == ['english_lowercase', 'english_uppercase', 'non_english', 'number.json', 'special']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c713869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in broken_file_contents:\n",
    "    # TODO: generate relative path to item using os.path.join(...)\n",
    "    path_to_item = ???\n",
    "    print(path_to_item) # Test until here, then comment out this print, and then address the rest of the TODOs\n",
    "    \n",
    "    # TODO: check if item is a file, if so print(path_to_item, \"is a file\").\n",
    "    #       Recall that os.path.isfile(...) enables you to do this\n",
    "    #       If not, print(path_to_item, \"is a directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe37c517",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "```\n",
    "broken_file/english_lowercase is a directory\n",
    "broken_file/english_uppercase is a directory\n",
    "broken_file/non_english is a directory\n",
    "broken_file/number.json is a file\n",
    "broken_file/special is a directory\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0459da1-b3b9-4ef1-b83e-2be7c19d96bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell should be pasted into your p11 notebook\n",
    "\n",
    "def get_all_paths_in(directory):\n",
    "    # You can borrow the idea from your Task 2.3\n",
    "    # TODO: initialize an empty list\n",
    "    # TODO: invoke listdir function to get a list of files and directories inside `directory`\n",
    "    # TODO: iterate over the list of files and directories\n",
    "        # TODO: generate releative path using os.path.join(...) \n",
    "        # TODO: if the current entry is a file, add it into the list\n",
    "        # TODO: if the current entry is a directory, recursively explore this sub-directory\n",
    "    # TODO: return the sorted list\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d67094",
   "metadata": {},
   "source": [
    "Expected Output:\n",
    "\n",
    "```python\n",
    "['broken_file/english_lowercase/a_to_m/a_to_m.json', \n",
    "'broken_file/english_lowercase/rest.json',\n",
    "'broken_file/english_uppercase/A_to_E/A/A.json', \n",
    "'broken_file/english_uppercase/A_to_E/E.json',\n",
    "'broken_file/english_uppercase/A_to_E/rest/rest.json', \n",
    "'broken_file/english_uppercase/F_to_K/F_to_H.json',\n",
    "'broken_file/english_uppercase/F_to_K/I_to_K/I/I.json', \n",
    "'broken_file/english_uppercase/F_to_K/I_to_K/rest.json',\n",
    "'broken_file/english_uppercase/L_to_Q/O.json', \n",
    "'broken_file/english_uppercase/L_to_Q/rest/L_to_N/M.json',\n",
    "'broken_file/english_uppercase/L_to_Q/rest/L_to_N/rest/rest.json', \n",
    "'broken_file/english_uppercase/L_to_Q/rest/P_to_Q.json',\n",
    "'broken_file/english_uppercase/R_to_W.json', \n",
    "'broken_file/english_uppercase/rest.json',\n",
    "'broken_file/non_english/korean.json', \n",
    "'broken_file/non_english/rest/japanese/japanese.json',\n",
    "'broken_file/non_english/rest/rest.json', \n",
    "'broken_file/non_english/russian/russian.json',\n",
    "'broken_file/number.json', 'broken_file/special/special.json']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bff6c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a test for get_all_paths_in\n",
    "assert get_all_paths_in('broken_file') == \\\n",
    "[os.path.join('broken_file', 'english_lowercase', 'a_to_m', 'a_to_m.json'),\n",
    "                os.path.join('broken_file', 'english_lowercase', 'rest.json'),\n",
    "                os.path.join('broken_file', 'english_uppercase', 'A_to_E', 'A', 'A.json'),\n",
    "                os.path.join('broken_file', 'english_uppercase', 'A_to_E', 'E.json'),\n",
    "                os.path.join('broken_file', 'english_uppercase', 'A_to_E', 'rest', 'rest.json'),\n",
    "                os.path.join('broken_file', 'english_uppercase', 'F_to_K', 'F_to_H.json'),\n",
    "                os.path.join('broken_file', 'english_uppercase', 'F_to_K', 'I_to_K', 'I', 'I.json'),\n",
    "                os.path.join('broken_file', 'english_uppercase', 'F_to_K', 'I_to_K', 'rest.json'),\n",
    "                os.path.join('broken_file', 'english_uppercase', 'L_to_Q', 'O.json'),\n",
    "                os.path.join('broken_file', 'english_uppercase', 'L_to_Q', 'rest', 'L_to_N', 'M.json'),\n",
    "                os.path.join('broken_file', 'english_uppercase', 'L_to_Q', 'rest', 'L_to_N', 'rest', 'rest.json'),\n",
    "                os.path.join('broken_file', 'english_uppercase', 'L_to_Q', 'rest', 'P_to_Q.json'),\n",
    "                os.path.join('broken_file', 'english_uppercase', 'R_to_W.json'),\n",
    "                os.path.join('broken_file', 'english_uppercase', 'rest.json'),\n",
    "                os.path.join('broken_file', 'non_english', 'korean.json'),\n",
    "                os.path.join('broken_file', 'non_english', 'rest', 'japanese', 'japanese.json'),\n",
    "                os.path.join('broken_file', 'non_english', 'rest', 'rest.json'),\n",
    "                os.path.join('broken_file', 'non_english', 'russian', 'russian.json'),\n",
    "                os.path.join('broken_file', 'number.json'),\n",
    "                os.path.join('broken_file', 'special', 'special.json')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f0b520",
   "metadata": {},
   "source": [
    "If the above assertion failed, make sure you sorted the list of paths before you returned it from your `get_all_paths_in` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62c9a5e-7689-4fa7-bc9a-b9a88003c6fb",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3334d350-e06a-4c08-8ac1-026eef3b283b",
   "metadata": {},
   "source": [
    "## Segment 3: Scatterplot\n",
    "### Task 3.1: Practice drawing scatterplot\n",
    "\n",
    "In lab-p9, we learned how to draw a bar chart to visualize data. This time, we introduce scatterplot to visualize the correlation between x-axis data and y-axis data. And, we will use some toy datasets to practice how to visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae58311-a12d-4694-895e-0c9d6a32942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell should be pasted into your p11 notebook\n",
    "def scatter(x, y, xlabel=\"please label me!\", ylabel=\"please label me!\"):\n",
    "    df = pandas.DataFrame({\"x\":x, \"y\":y})\n",
    "    ax = df.plot.scatter(x=\"x\", y=\"y\", color=\"black\", fontsize=16, ylim=0)\n",
    "    ax.set_ylabel(ylabel, fontsize=16)\n",
    "    ax.set_xlabel(xlabel, fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646baa00-2f45-4633-836c-7daaf7d885f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's play with toy dataset to draw scatter plot for it.\n",
    "## X axis data are in `toy_dataset_x`, and y axis data are in `toy_dataset_y`\n",
    "\n",
    "toy_dataset_x = [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 8.0, 8.0, 8.0]\n",
    "toy_dataset_y = [4.1, 4.3, 4.2, 5.8, 6.0, 6.4, 8.4, 8.0, 7.9, 8.3, 8.1, 8.2, 1.9, 2.1, 1.0]\n",
    "\n",
    "scatter(toy_dataset_x, toy_dataset_y, \"X\", \"Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f8ef6d-5b0b-4ad5-8307-82caeffdb65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can also create a dictionary and use `scatter` function to draw scatter plot.\n",
    "## Key values in `toy_dataset_dict` are data for x axis, and values in `toy_dataset_dict` are data for y axis.\n",
    "## Please label x axis and y axis in scatter plot by \"X\" and \"Y\".\n",
    "\n",
    "toy_dataset_dict = {0.0: 6.8, 5.0: 2.0, 4.0: 1.0, 8.0: 1.2, 6.0: 0.7, 7.0: 1.5}\n",
    "\n",
    "# Recall that you can use keys() method to extract a dict keys\n",
    "# and values() method to extract the values\n",
    "scatter(???, ???, \"X\", \"Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46093c7",
   "metadata": {},
   "source": [
    "Remember how dictionary keys are always unique? That can sometimes backfire...\n",
    "Try making a dictionary where `toy_dataset_x` are the keys, and `toy_dataset_y` are the values.\n",
    "Then try plotting this dictionary the same way you plotted `toy_dataset_dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6916773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_data_dict_2 = ???\n",
    "\n",
    "scatter(???, ???, \"X\", \"Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9815f7a8",
   "metadata": {},
   "source": [
    "This third plot *should* be identical to the first one - it uses the same x and y values. But the plot now has much fewer points. Is this a good thing or bad thing? It depends on whether you want multiple points with the same x value to be plotted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2ed4b1-d1a8-4e34-a1a7-e67dbe348be9",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b50fa07-4c66-4915-a1ce-fc2539c3e408",
   "metadata": {},
   "source": [
    "### Task 3.2: Remove outliers in scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62c6e64-b235-4ca8-873b-30199bc46eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## You can find that there is an outlier datapoint in our dataset located at (0.0, 6.8).\n",
    "\n",
    "## You can either use dict comprehension or regular code to populate a new dict\n",
    "## where you conditionally retain any key:value pair whose value is <= 3\n",
    "## Use this new dictionary to create a scatter plot\n",
    "\n",
    "toy_dataset_no_outliers = ???\n",
    "scatter(???, ???, \"X\", \"Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c247cb-0f48-4426-aeeb-a82225cef7a5",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456e123a-1238-4746-872d-3a4bfaa8ebaf",
   "metadata": {},
   "source": [
    "### Task 3.3: Practice scatterplot with videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d242a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for video_id in videos:\n",
    "    print(videos[video_id][\"views\"], videos[video_id][\"likes\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfa2b3b-1a4f-4e09-a749-eb9e415b8f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's visualize the correlation between \"views\" and \"likes\"\n",
    "\n",
    "## You can either use dict comprehension or regular code to populate a new dict\n",
    "## to map \"views\" to \"likes\" for every video\n",
    "views_to_likes_dict = ???\n",
    "\n",
    "## Then use the new dictionary for scatter plot visualization\n",
    "## X-axis should be your \"views\" and y-axis should be your \"likes\". Don't forget to label them.\n",
    "scatter(???, ???, ???, ???)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
